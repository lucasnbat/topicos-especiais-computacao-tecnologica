# -*- coding: utf-8 -*-
"""estudo-aula-3-tect.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15AuPgS5okKTNJ32cLWAVVYDXlyJpl1Uc
"""

# média
import numpy
speed = [99,86, 87,88, 111,86, 103,87, 94,78, 77,85, 86]
x = numpy.mean(speed)
print (x)

# mediana
import numpy
speed = [99,86, 87,88, 111,86, 103,87, 94,78, 77,85, 86]
x = numpy.median(speed)
print (x)

# mediana com dois valores no meio (quantidade par)
import numpy
speed = [99,86,87,88,86,103,87,94,78,77,85,86]
x = numpy.median(speed)
print(x)

# moda (número que mais aparece)
from scipy import stats
speed = [99,86,87,88,86,103,87,94,78,77,85,86]
x = stats.mode(speed)
print (x)

# desvio padrão (σ)
import numpy
speed_1 = [86,87,88,86,87,85,86]
speed_2 = [32,111,138,28,59,77,97]
x = numpy.std(speed_1)
y = numpy.std(speed_2)
print ('speed_1:', x)
print ('speed_2:', y)

# variância (σ 2)
import numpy
speed = [32,111,138,28,59,77,97]
x = numpy.var(speed)
print(x)

# percentiles
import numpy
ages = [5, 31,43, 48,50, 41,7, 11,15, 39,80, 82,32,2,8,6, 25,36, 27,61, 31]
x = numpy.percentile(ages, 75)
print (x) # 43.0 --> indica que 75% das pessoas tem 43 anos ou menos

import numpy
x = numpy.random.uniform(0.0,5.0,250) # 250 numeros flutuantes aleatórios entre 0 e 5
print (x)

import numpy
import matplotlib.pyplot as plt

x = numpy.random.uniform(0.0, 5.0, 250)

plt.hist(x, 5) # 5 barras --> 52 valores entre 0 e 1, 48 valores entre 1 e 2...
plt.show()

import numpy
import matplotlib.pyplot as plt

x = numpy.random.uniform(0.0, 5.0, 100000) # 100.000 números com vírgula de 0 a 5

plt.hist(x, 100) # gráfico histograma de 100 barras
plt.show()

import numpy
import matplotlib.pyplot as plt

# veja que mudamos para distr. normal/gaussiana (gráfico de sino)
# valor médio = 5.0
# desvio padrão = 1.0
# logo, a maioria dos valores se aproximam de 5, no meio
x = numpy.random.normal(5.0,1.0,100000)

print (x)
plt.hist(x, 100)
plt.show()

import matplotlib.pyplot as plt

x = [5,7,8,7,2, 17,2,9,4, 11,12,9,6] # idade do carro
y = [99,86,87,88,111,86,103,87,94,78,77,85,86] # velocidade do carro

plt.scatter(x,y) # gera graficos de dispersão usando x (eixo x) e y (eixo y)
plt.show()

import numpy
import matplotlib.pyplot as plt

# distr. normal com 1000 numeros, média 5, desvio padrão 1
x = numpy.random.normal(5.0,1.0,1000)

# distr. normal com 1000 numeros, média 10, desvio padrão 2
y = numpy.random.normal(10.0,2.0,1000)

plt.scatter(x,y) # cria gráfico de dispersão
plt.show()

# conclusão: pontos de x muito proximos de 5 e de y muito próximos de 10

# regressão linear

import matplotlib.pyplot as plt
from scipy import stats

x = [5,7,8, 7, 2, 17, 2, 9, 4, 11, 12, 9, 6]
y = [99, 86, 87, 88, 111, 86, 103, 87, 94, 78, 77, 85, 86]

# destructuring para pegar variaveis importantes da regressão linear
slope, intercept, r, p, std_err = stats.linregress(x,y)

# aparentemente uma função para desenhar a linha ("valor x equivale a valor y")
def myfunc (x):
  return slope * x + intercept

# gera modelo usando a função criada com os valores de x (var independente)
# isso cria um vetor com os valores y que serão cruzados com os valores x e criar a linha
mymodel = list(map(myfunc, x))

plt.scatter(x, y) # desenha grafico dispersão original (bolinhas)
plt.plot (x, mymodel) # desenha linha de regressão
plt.show() # exibe o diagrama

# verificando coeficiente de correlação para checar se dá para prever algo
# O rvalor varia de -1 a 1, onde 0 significa nenhum relacionamento e 1 (e -1)
# significa 100% relacionado

from scipy import stats

# dois conjuntos, como antes
x = [5,7,8, 7, 2, 17, 2, 9, 4, 11, 12, 9, 6]
y = [99, 86, 87, 88, 111, 86, 103, 87, 94, 78, 77, 85, 86]

# destructuring do modulo de regressão, veja o r ali
slope, intercept, r, p, std_err = stats.linregress(x, y)

# printando
print (r)

# -0.758591524376155 = relação não perfeita, mas pode ser usada para prever algo

import matplotlib.pyplot as plt
from scipy import stats

x = [5,7,8, 7, 2, 17, 2, 9, 4, 11, 12, 9, 6]
y = [99, 86, 87, 88, 111, 86, 103, 87, 94, 78, 77, 85, 86]

# destructuring para pegar variaveis importantes da regressão linear
slope, intercept, r, p, std_err = stats.linregress(x,y)

# aparentemente uma função para desenhar a linha ("valor x equivale a valor y")
def myfunc (x):
  return slope * x + intercept

# prevendo velocidade de um carro de 10 anos
speed_predicted = myfunc(10)

print (speed_predicted)

# escrevendo um exemplo onde a regressão não seria o melhor método para previsão

import matplotlib.pyplot as plt
from scipy import stats

x = [89, 43, 36, 36, 95, 10, 66, 34, 38, 20, 26, 29, 48, 64, 6, 5, 36, 66, 72, 40]
y = [21,46, 3, 35, 67, 95, 53, 72, 58, 10, 26, 34, 90, 33, 38, 20, 56, 2, 47, 15]

slope, intercept, r, p, std_err = stats.linregress (x, y)

def myfunc (x) :
  return slope * x + intercept

mymodel = list(map (myfunc, x) )

#  O resultado de R: 0,013 indica um relacionamento muito ruim e nos diz que
# este conjunto de dados não é adequado para regressão linear.
print ('R de relacionamento:', r)
plt.scatter (x, y)
plt.plot (x, mymodel)
plt.show ()

# esse gráfico abaixo é o retrato de uma representação ruim para previsão...
# praticamente todo valor de x que você der, vai dar o mesmo valor de y

# Se a regressão linear não é o melhor método, pode-se tentar a regressão polinomial

import matplotlib.pyplot as plt
import numpy

x = [1,2,3,5, 6,7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 21, 22]
y = [100,90, 80, 60, 60, 55, 60, 65, 70, 70, 75, 76, 78, 79, 90, 99, 99, 100]

# criando valores de y (modelo de grafico) com a biblioteca de regressão polinomial
mymodel = numpy.poly1d(numpy.polyfit(x,y,3))

# cria a linha passando valores de onde começará (posição x= 1)
# e onde terminará (posição x= 22)
myline = numpy.linspace(1,22,100)

plt.scatter(x, y)

# desenhando linha de regressão polinomial
plt.plot(myline, mymodel(myline))

plt.show()

# mas... se o R-squared (outra métrica de relacionamento) não for boa, nem
# a regressão polinomial vai dar para usar no seu conjunto de dados

# O valor de r ao quadrado varia de 0 a 1, onde 0 significa nenhum relacionamento
# e 1 significa 100% relacionado.

import numpy
from sklearn.metrics import r2_score

x = [1,2,3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 21, 22]
y = [100,90, 80, 60, 60, 55, 60, 65, 70, 70, 75, 76, 78, 79, 90, 99, 99, 100]

mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))
print (r2_score(y, mymodel(x))) # 0.9432150416451026 (relação muito boa)

# prevendo velocidade de um carro que passa por volta das 17 horas

import numpy
from sklearn.metrics import r2_score

x = [1,2,3, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 21, 22]
y = [100,90, 80, 60, 60, 55, 60, 65, 70, 70, 75, 76, 78, 79, 90, 99, 99, 100]

mymodel = numpy.poly1d(numpy.polyfit(x, y, 3))

speed_predicted = mymodel(17)

print (speed_predicted) # carro passará provavelmente a 88,87 km/h

# vide exemplo de R² ruim no pdf

# regressão múltipla
# ex. no vscode